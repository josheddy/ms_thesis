\chapter{Future Work}

\section{System Improvements}

Experimentation with \texttt{kalman\_sense} has revealed a number of areas for improvement. Speaking generally, the system needs enhancements to become more accurate and more robust to sensor dropout. Further development of this work would likely center on three main areas:
\begin{enumerate}
    \item Integration of new sensors,
    \item Improvements for current sensors, and
    \item Refinements to the underlying algorithm.
\end{enumerate}
Each of these could produce a marked improvement to the system in accuracy, robustness, or both. Particular use cases, Concepts of Operations (CONOPS), and desired performance metrics would likely drive the selection of which of these areas to tackle.

\subsection{Integration of New Sensors}
The accuracy and robustness of the system could be augmented by the integration of additional sensors, including but not limited to
\begin{enumerate}
    \item One or more GPS receivers (particularly Real Time Kinematic\footnote{\url{https://en.wikipedia.org/wiki/Real_Time_Kinematic}} GPS),
    \item A pressure altimeter,
    \item A 3-axis magnetometer,
    \item One or more laser rangefinders,
    \item One or more forward-facing cameras (preferably depth cameras, such as RGB-D),
    \item One-dimensional, multi-dimensional, or scanning LIDAR\footnote{``Light Detection and Ranging,'' \url{https://en.wikipedia.org/wiki/Lidar}}.
\end{enumerate}
We have previously mentioned work from the GRASP Lab (\cite{Shen2011}) that has demonstrated the efficacy of similar UKF frameworks in indoor-outdoor transitions and in navigating confined spaces using an expanded suite of sensors. In the case where more than one sensor can be used to observe a given vehicle state variable, those multiple sensors can be used to check one another and even perform real-time, in-air calibration. The system developed in this thesis has the advantage of being hardware-minimal in that it depends on only two sensors (the IMU and ventral camera), but this convenience comes at the cost of robustness as either sensor presents a single point of failure. Moreover, the sensors have no overlap in that neither can observe any of the states observed by the other. This eliminates the possibility of checking one sensor against the other with high confidence. Introducing a ventral laser rangefinder or pressure altimeter would allow for much more precise measurement of the vehicle's altitude and would allow for in-flight re-initialization of any metric SLAM/VO algorithm.

With the exception of certain sensors such as scanning LIDAR, which can cost tens of thousands of dollars, and RTK-GPS, which often falls in the same price range, these proposed new sensors would be inexpensive additions to the vehicle. Given the sophistication of current miniaturized sensors, it is not unreasonable to expect sub-meter or centimeter-level position accuracy from vehicles weighing fewer than fifteen pounds (including a substantial sensor payload) and costing less than 20,000~USD. It has been the case for a number of years now that meter-level accuracy could be taken for granted with ``toy'' quadcopters using only MEMS\footnote{\url{https://en.wikipedia.org/wiki/Microelectromechanical_systems}} IMUs and sub-\$100 GPS receivers. The trend of miniaturization has made more and more sensors of better and better quality increasingly available in the weight- and cost-constrained world of aerial robotics. A variety of inexpensive off-the-shelf autopilots, such as the Pixhawk~2.1\footnote{\url{http://www.proficnc.com/}}, already boast triple-redundant IMUs and support for multiple GPS modules. Many of the hardware integration challenges that once plagued hobbyists and researchers have been eliminated by popular demand for user-friendly drones.

The organization of \texttt{kalman\_sense}'s code base is such that the integration of new sensors would require only the addition of new callback functions and ROS subscribers, as opposed to a full redesign or any major edits to the existing code. By a similar token, a new SLAM or VO algorithm could also be used in place of PTAM, allowing an ``apples-to-apples'' comparison of different vision algorithms. For example, Donavanik et al.\ (\cite{Donavanik2016}) have identified a new algorithm known as ORB-SLAM (\cite{Mur-Artal2015}) as a promising candidate for robust SLAM, already implemented in ROS. Because of ROS's sophisticated ecosystem of interoperable packages and message formats, any pose sensor employing the same message type as PTAM could plug in to \texttt{kalman\_sense} in a matter of seconds.

Much of the design thinking that went into the design of the \texttt{kalman\_sense} package was focused on this particular possibility. The aircraft of the future will be vehicles laden with a vast suite of heterogeneous sensors, the outputs of which are at any given time being used not only for inner-loop and outer-loop flight control but also for self-calibration, real-time diagnostics, and operator telemetry. Future UAVs will be akin to floating laboratories, carrying numerous means of measurement for all manner of self-sensing as well as scientific applications.

\subsection{Improvements for Current Sensors}

For improved pose measurements, a more robust implementation of PTAM could be written and the same experiments could be repeated for comparison. PTAM's rotation errors and inability to eliminate lens distortion pose severe limitations to its effectiveness in small UAS navigation. Moreover, if a rewritten implementation were able to interface to a downward-facing rangefinder, the initialization process could be eliminated altogether. The problem with this is that making these changes would likely require a major rewrite, a project that could only feasibly be undertaken by an experienced team of computer vision researchers and software developers. The mere cost in terms of both time and labor would likely make this an unappealing proposition, especially if other ready-made SLAM/VO algorithms were available to serve as PTAM replacements.

Processing power will also be central to the system's effectiveness during deployment on a real aircraft. This research is in many ways the product of recent advances in computing power. The advent of miniature desktop computers, such as the Intel NUC\footnote{``Next Unit of Computing,'' \url{https://en.wikipedia.org/wiki/Next_Unit_of_Computing}}, as well as power-efficient Graphics Processing Units\footnote{\url{https://en.wikipedia.org/wiki/Graphics_processing_unit}} (GPUs) has made a new frontier of estimation and localization algorithms accessible for the first time in the UAV world. A simple and generally inexpensive approach to augmenting the \texttt{kalman\_sense} system would thus be the inclusion of top-of-the-line lightweight computing hardware. With modern onboard computers, even the need for cross-platform code compilation (so-called ``transpiling'') is eliminated because these computers employ the same x86 architecture used by developers.

\subsection{Refinements to the Underlying Algorithm}





\section{Future Experiments}

\section{System Applications}

Historically, man-portable drones capable of indoor reconnaissance have been computationally constrained due to restrictions on both size and weight. Recent advances in miniaturized desktop computers, as well as low-power Graphics Processing Units (GPUs), have enabled a new class of computationally intensive algorithms to run aboard small aircraft without degrading flight time or other per-formance metrics. Specifically, small drones now present a viable platform for high-fidelity Simultaneous Localization and Mapping (SLAM), visual object recognition, and state estimation algorithms employing numerous heterogeneous sensors. This proposal envisions exploratory analysis in the latter, combining previously inaccessible continuous-state filtering methodologies with novel SLAM implementations to generate highly accurate pose estimates for small rotorcraft in unstructured indoor and outdoor environments.

The work will involve instrumenting a number of small multirotor aircraft with GPS, cameras, pressure altimeters, inertial measurement units, laser rangefinders, LIDAR, and other sensors. Novel sensor fusion algorithms (based, for example, on the Unscented Kalman Filter) will be employed to intelligently combine sensor readings for robust navigation, even during GPS blackouts. The objective of this work would be to explore both indoor and outdoor behavior of these algorithms, as well as their reliability in the presence of dynamic obstacles, such as moving vehicles or human beings. The focus will remain on instrumenting and programming these aircraft to be able to operate with both a minimum of \textit{a priori} knowledge of their environment and a minimum amount of hardware, owing to the need for man-portability.

The goal of this work is to produce robust but generic sensor fusion algorithms applicable to numerous robotic vehicles, be they autonomous or teleoperated, aerial or terrestrial. These results would empower a new generation of intelligent unmanned systems, capable of robust tracking of friendly and hostile elements, remote observation of roads and vehicle-related hazards, and on-demand delivery of materiel in theater. This research would similarly support a number of human-machine teaming initiatives and would augment the reconnaissance and supply-chain capabilities of human combat units.
