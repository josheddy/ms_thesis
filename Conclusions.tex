\chapter{Conclusions and Future Work}

\section{Conclusions}

In the course of this research, we have developed an algorithm for fusion of IMU and SLAM data for localization of a small aircraft capable of hovering flight. We have presented not only an Unscented Kalman Filter formulation for this purpose, but also two corrective measures for maintaining quaternion continuity and deriving velocity measurements from pose readings to maintain numerical stability in the filter's output. We have also presented software implementation details related to the creation of a ROS package performing this fusion algorithm and described a number of architectural traits of this package encouraging and allowing for the adaptation of this work to systems other than small rotorcraft.

This work is largely motivated by the confluence of increased computing power and increased payload capacity for small UAS. The system developed in this thesis is meant to empower the roboticist researcher with a general state estimation framework useful for modeling a wide range of systems with arbitrary levels of fidelity. The experiments detailed in Chapters~\ref{ch:Exp_Design} and \ref{ch:Exp_Results} deployed the system in an indoor navigation scenario to characterize its behavior in a realistic environment where GPS would never be available as a backup sensing modality. In box pattern tests, the system consistently maintained a mean total positional error of less than 7~cm with overall maximum total error never exceeding 25.96~cm. By these performance metrics, the UKF framework is more accurate than today's smartphone-grade GPS receivers and on par with similar sensor fusion systems detailed in Chapter~\ref{ch:Prior_Work}.

Nevertheless, the system faces several critical challenges. The PTAM implementation used during the experiments suffers from a number of serious defects. This PTAM implementation exhibits aberrant $z$-position estimates over flat terrain, erroneously conflates rotations with translations, and appears not to eliminate camera lens distortion. These defects severely limit the possible use cases for the system, assuming the same PTAM implementation is used. For effective use in non-laboratory scenarios, the vehicle would have to fly in pure translation (that is, without substantial rotations). Though this may seem like an odd requirement, modern hobby-grade autopilots, such as the Pixhawk, already allow for precisely this type of flight.

Perhaps the more stringent requirement on this system is that it be used in environments with ample visual geometry. The SLAM algorithm used in experimentation was susceptible to losing tracking if the density of visible features was not sufficiently high. Thus, high-density environmental features would be a necessary condition for any SLAM/VO algorithm, meaning that the system could be deployed usefully only in areas having a vast array of high-contrast features (and sufficient lighting by which to see them).

With all of this being said, the UKF framework developed here still represents a useful jumping-off point for further work. Future developments in this area (explored in detail in the next section) will likely revolve around increasing accuracy and robustness, the two principle challenges of any navigation system. Even the much-glorified Global Positioning System is not without its systemic faults and environmental limitations. Because of its generality, this work could be applied to great effect in numerous state estimation scenarios. Beyond rotorcraft and fixed-wing airplanes, this UKF framework could be adapted for use with spacecraft, surface vessels, undersea vehicles, and automobiles. Due to increasing demand for intelligent systems and unmanned vehicles of many varieties, it is likely that research in this area will continue for decades to come. In any case, the emphasis will likely remain on higher accuracy and greater robustness. With the growing trend of miniaturization and the increasing density of human populations, the need for ever more precise localization will always be present.

\section{Future Work}

\subsection{System Improvements}

Experimentation with the \texttt{kalman\_sense} ROS package has revealed a number of areas for improvement. Speaking generally, the system needs enhancements to improve accuracy and to become more robust with respect to potential sensor malfunction. Further development of this work to augment accuracy and robustness would center on three main areas:
\begin{enumerate}
    \item Integration of new sensors,
    \item Improvements for current sensors, and
    \item Refinements to the underlying algorithm.
\end{enumerate}
Modifications to any or all of these areas would produce a marked improvement to the system in terms of both accuracy and robustness. For maximal effectiveness in adverse conditions, the system's sensors would need to be both individually robust and collectively redundant, so that complementary sensors could compensate for the loss of another sensor's information.

\subsubsection{Integration of New Sensors}
The accuracy and robustness of the system could be augmented by the integration of additional sensors, including but not limited to, the following:
\begin{enumerate}
    \item One or more GPS receivers (particularly Real Time Kinematic\footnote{\url{https://en.wikipedia.org/wiki/Real_Time_Kinematic}} GPS),
    \item A pressure altimeter,
    \item A 3-axis magnetometer,
    \item One or more laser rangefinders,
    \item One or more forward-facing cameras (preferably depth cameras, such as RGB-D),
    \item One-dimensional, multi-dimensional, or scanning LIDAR\footnote{``Light Detection and Ranging,'' \url{https://en.wikipedia.org/wiki/Lidar}}.
\end{enumerate}

We previously mentioned work from the GRASP Lab (\cite{Shen2011}) that demonstrated the efficacy of similar UKF frameworks in indoor-outdoor transitions and in navigating confined spaces using an expanded suite of sensors. In the case where more than one sensor is used to observe a given vehicle state variable, those multiple sensors check one another and can even perform real-time, in-air calibration. The system developed in this thesis has the advantage of being hardware-minimal in that it depends on only two sensors (the IMU and the ventral camera), but this convenience comes at the cost of robustness because either sensor presents a single point of possible failure. Moreover, the sensors have no overlap. Neither can observe any of the states observed by the other. This eliminates the possibility of checking one sensor against the other. Introducing a ventral laser rangefinder or pressure altimeter would allow for much more precise measurement of the vehicle's altitude and would allow for in-flight re-initialization of any metric SLAM/VO algorithm.

With the exception of certain sensors such as scanning LIDAR, which can cost tens of thousands of dollars, and RTK-GPS, which often falls in the same price range, these proposed new sensors would be inexpensive additions to the vehicle. Given the sophistication of current miniaturized sensors, it is not unreasonable to expect sub-meter or centimeter-level position accuracy from vehicles weighing fewer than fifteen pounds (including a substantial sensor payload) and costing less than 20,000~USD. It has been the case for a number of years now that meter-level accuracy could be taken for granted with ``toy'' quadcopters using only MEMS\footnote{``Microelectromechanical systems,''\\ \url{https://en.wikipedia.org/wiki/Microelectromechanical_systems}} IMUs and sub-\$100 GPS receivers. The trend of miniaturization has made more and more sensors of better and better quality increasingly available in the weight- and cost-constrained world of aerial robotics. A variety of inexpensive off-the-shelf autopilots, such as the Pixhawk~2.1\footnote{\url{http://www.proficnc.com/}}, already boast triple-redundant IMUs and support for multiple GPS modules. Many of the hardware integration challenges that once plagued hobbyists and researchers have been resolved by engineering developments stemming from popular demand for user-friendly drones.

The organization of the \texttt{kalman\_sense} package's code base is such that the integration of new sensors would require only the addition of new callback functions and ROS subscribers, as opposed to a full redesign or major edits to the existing code. Further, a new SLAM or VO algorithm could also be used in lieu of PTAM, allowing an ``apples-to-apples'' comparison of different visual localization algorithms. For example, Donavanik et~al.\ \cite{Donavanik2016} have identified a new algorithm known as ORB-SLAM \cite{Mur-Artal2015} as a promising candidate for robust SLAM, already implemented in ROS. Because of ROS's sophisticated ecosystem of interoperable packages and message formats, any pose sensor employing the same message type as PTAM could plug in to \texttt{kalman\_sense} in a matter of seconds.

Much of the design thinking that went into the \texttt{kalman\_sense} package was focused on this particular possibility. The aircraft of the future will be vehicles laden with a vast suite of heterogeneous sensors, the outputs of which would, at any given time, be used not only for inner-loop and outer-loop flight control, but also for self-calibration, real-time diagnostics, and operator telemetry. Future UAVs will be akin to floating laboratories, mobile arrays of cutting-edge measurement systems allowing remote sensing over areas of several square miles.

\subsubsection{Improvements for Current Sensors}

For improved pose measurements, a more robust implementation of PTAM could be written and the same experiments could be repeated for comparison. PTAM's rotation errors and inability to eliminate camera lens distortion constitute severe limitations to its effectiveness in small UAS navigation. Moreover, if a rewritten formulation were able to interface with a downward-facing rangefinder, the initialization process could be eliminated altogether. The drawback is that making these changes would require a major software rewrite, a project that could be feasibly undertaken only by an experienced team of computer vision researchers and software developers. The mere cost in terms of both time and labor would likely make this an unappealing proposition, especially if other ready-made SLAM/VO algorithms were available to serve as PTAM replacements.

Processing power will also be central to the system's effectiveness during deployment on a real-world mission. This research is in many ways the product of recent advances in computing power. The advent of miniature desktop computers, such as the Intel~NUC\footnote{``Next Unit of Computing,'' \url{https://en.wikipedia.org/wiki/Next_Unit_of_Computing}}, as well as power-efficient Graphics Processing Units\footnote{\url{https://en.wikipedia.org/wiki/Graphics_processing_unit}} (GPUs) has made a new frontier of estimation and localization algorithms easily accessible for the first time in the UAV world. A simple and generally inexpensive approach to augmenting the \texttt{kalman\_sense} system would thus be the inclusion of top-of-the-line lightweight computing hardware. With modern onboard computers, even the need for cross-platform code compilation (so-called ``transpiling'') is eliminated because these computers employ the same x86 architecture used by most software developers.

\subsubsection{Refinements to the Underlying Algorithm}

The UKF formulation itself presents another set of opportunities for improvement. In particular, better process and measurement noise modeling would allow for increased accuracy. As described previously, the noise covariance matrices used during the experiments were only rough, static models meant to overestimate the Gaussian noise in the system. In practice, it would be better to replace these with time-varying matrices with terms more closely matching the intrinsic parameters of the system. Due to the high degree of coupling between state variables and the fundamental nonlinearity of the process model, this type of work was considered to be outside the scope of my thesis. In the future, however, a better $\mathbf{Q}$ matrix could be determined, perhaps by application of autocovariance and system identification methods. Moreover, any new sensor integrated into the system would require its own $\mathbf{R}$ matrix detailing its particular idiosyncrasies. With this done, the focus of attention could be on tuning the $\mathbf{Q} / \mathbf{R}$ ratio of each sensor, thus making the system even more faithful to known sensor parameters. With more sensors, self-calibration techniques such as those employed in \cite{Weiss2012} could also be implemented to avoid the process of reinitializing one or more sensors in mid-air.

\subsection{Future Experiments}

Using a SLAM/VO algorithm that addresses pure rotation and camera lens distortion would be the easiest and most cost-effective way to improve the system. Testing different visual localization algorithms would thus be an appealing avenue of inquiry. It would behoove the researcher to characterize the system's behavior under the same conditions that caused the PTAM-based implementation to fail. In particular, experiments that include pure rotations and longer translations, as well as simulated flight movement over uneven but otherwise virtually unchanging terrain would mimic real-world flight missions more closely and provide a more holistic understanding of the system's effectiveness. Additionally, mounting the sensor suite on the underside of a UAV would allow for the collection of real-world flight data, which could shed light on the system's speed limits and behavior in the presence of in-flight vibrations.

After integrating new sensors, new experiments could be devised to characterize the system's effectiveness during sensor blackouts---for example, during an indoor-outdoor transition after integrating a GPS receiver. Experiments such as this could then inform the design of heuristic models for recognizing sensor degradation and perhaps even consensus-based estimation strategies. 
