\chapter{Prior Work}

\subsection{Unscented Filtering and Nonlinear Estimation}

In \cite{Julier1997,Julier2004}, Julier and Uhlmann discuss the application of the extended Kalman filter (EKF) as an estimation algorithm and the associated difficulties. The EKF contains inherent problems and works best with linear systems. These limitations led to the development of the unscented transformation (UT) for nonlinear applications. In this paper, Julier and Uhlmann describe the unscented transformation (UT) and its benefits including easier implementation and improved accuracy. UT offers greater accuracy and reliability by applying higher order information using sigma points to the traditional mean and covariance information associated with linear applications. The authors provide examples, which may be tailored, that show how UT overcomes the limitations of the EKF.

\subsection{A Multi-State Constraint Kalman Filter for Vision-aided Inertial Navigation}

In this paper, Mourikis et al. expand investigation of the familiar topic of Vision-aided Inertial Navigation, with particular emphasis on small, low-cost, low-weight systems, including unmanned aerial vehicles (UAVs) using a monocular camera. Because technical advances have been made in the manufacture of inertial sensors, these robotic systems are capable of producing high precision state estimations even in uncontrolled urban environments, without utilizing a 3D feature position in the filter state vector of the Extended Kalman Filter (EKF). The exceptional accuracy produced in this real-time, real-world pose estimation model is highly desirable because it produces images that are rich in high-dimensional measurements. This robustness, however, invariably comes at a cost of computational complexity in the EKF-based algorithm, a trade-off that is unavoidable in the present state-of-the-art for vision-aided inertial navigation systems.

\subsection{Monocular-SLAM–Based Navigation for Autonomous Micro Helicopters in GPS-Denied Environments}

Autonomous micro aerial vehicles (MAVs) provide access to environments that are difficult to access. Further, they mitigate the risk to people and the environment. For many applications, the MAV must navigate in a GPS-denied environment. This paper presents an approach to navigation that relies on a micro helicopter, a single camera, and onboard inertial sensors. A monocular simultaneous localization and mapping (SLAM) framework stabilizes the vehicle, which is used to overcome the issues with drift. This research is important because urban canyons limit GPS availability. The authors, in this paper, show that autonomous navigation in a GPS-denied environment is achievable.

\subsection{Autonomous Multi-Floor Indoor Navigation with a Computationally Constrained MAV}

In this paper \cite{Shen2011}, Shen et al. extend the work of other authors on the topic of autonomous MAV navigation, particularly as it relates to stable indoor flight and GPS-denied localization in constrained multi-floor environments. The research distinguishes itself by emphasizing the use of onboard sensors only, as well as fully autonomous, real-time internal computational capabilities, with no hands-on user interaction beyond basic high-level commands. The research extends to multi-floor MAV operation with loop closure. It also addresses specially designed controllers to help compensate for sudden changes in wind velocity and air flow as the MAV traverses constrained low-clearance areas with potentially strong aerodynamic disturbances.

\subsection{Real-Time Metric State Estimation for Modular Vision-Inertial Systems}

Stephan Weiss and Roland Siegwart developed an algorithm that provides a metric scale to estimate that estimates monocular visual odometry or monoSLAM approaches. The authors accomplished the development of the metric scale by the addition of an inertial sensor with a three-axis accelerometer and gyroscope. Stephan Weiss and Roland Siegwart created a modular solution that is based on an Extended Kalman Filter (EKF) and provides both simulated results and data-based results. In this paper, the authors discuss their unique approach, its applications, versatility, and reliability of their estimating algorithm for visual odometry, such as visual SLAM, in real-time.

\subsection{Versatile Distributed Pose Estimation and Sensor Self-Calibration for an Autonomous MAV}

The authors present a versatile framework to enable autonomous ﬂights of a Micro Aerial Vehicle (MAV). The MAV has only slow, noisy, delayed and possibly arbitrarily scaled measurements available. The use of these measurements directly for position control is not practical since MAVs exhibit great agility in motion. In addition, these measurements often come from a selection of different onboard sensors, hence accurate calibration is crucial to the robustness of the estimation processes. In this article, Weiss, et al address the problems using an EKF formulation which fuses these measurements with inertial sensors. The authors not only estimate pose and velocity of the MAV, but also estimate sensor biases, scale of the position measurement and self (inter-sensor) calibration in real-time. The authors show that it is possible to obtain a yaw estimate from position measurements only. The authors demonstrate that the proposed framework is capable of running entirely onboard a MAV performing state prediction at the rate of 1 kHz. Their results illustrate that this approach is able to handle measurement delays (up to 500ms), noise (std. deviation up to 20 cm) and slow update rates (as low as 1 Hz) while dynamic maneuvers are still possible. Stephan Weiss et al present a detailed quantitative performance evaluation of the real system under the inﬂuence of different disturbance parameters and different sensor setups to highlight the versatility of our approach.

\subsection{Real-time Onboard Visual-Inertial State Estimation and Self-Calibration of MAVs in Unknown Environments}

In this paper, Weiss et al. explore the advantages of utilizing a high-performance navigation algorithm on a low-cost, low-weight micro aerial vehicle (MAV) equipped with a single camera and an inertial measurement unit (IMU) capable of both onboard processing and real-time operations, with focus on a speed estimation module to help control the speed of the MAV, all within an Extended Kalman Filter framework. The system was shown to be useful for real-time self-calibration of the sensor suite---critical to ensuring the robustness and flexibility of any state estimation process---and as a potential solution to some of the tracking failures common to keyframe-based modules.

\subsection{A Quadratic-Complexity Observability-Constrained Unscented Kalman Filter for SLAM}

In this paper, Huang et al. explore solutions to two Unscented Kalman Filter (UKF) limitations that exist in current state-of-the-art Simultaneous Localization and Mapping (SLAM) systems. Specifically, the authors address the problems of cubic complexity in the number of state pose estimates, and the inconsistencies in those estimates caused by a mismatch between the observability properties of statistically-linearized UKF systems and the observability properties of nonlinear systems. To address the problem of cubic complexity, the authors introduce a novel sampling strategy which produces a constant computational cost which, while linear in the propagation phase, is quadratic in the update phase. Although this new sampling strategy was primarily proposed for resolving the above-referenced SLAM problem, it also has potential usefulness in other nonlinear estimation applications. To address the problem of inconsistency in state estimations, the authors propose a new UKF algorithm which, due to the imposition of observability constraints, ensures that the linear regression computations of the modified UKF system produce results similar to those of nonlinear SLAM systems and, in the process, provide improved accuracy and consistency in state estimations. Importantly, these results have been validated with both real-world and simulation experiments. While the paper focused on 2D SLAM, the authors contend that their proposed methodology is also useful for robot localization in 3D, using inertial sensors.

