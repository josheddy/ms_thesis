\chapter{Prior Work}

\section{Development of the Unscented Kalman Filter}

In \cite{Julier1997}, Simon Julier and Jeffrey Uhlmann presented a nonlinear estimation approach for the Kalman Filter. Recognizing that most applications for autonomous navigation are fundamentally nonlinear in both their dynamics and their observation models, Julier and Uhlmann proposed the use of a set of discretely sampled ``sigma points'' to determine the mean and covariance of a probability distribution. By recasting the prediction and correction steps of the Kalman Filter in the form of unscented transforms (UTs), this new filter eliminates the need to calculate Jacobian matrices. Julier and Uhlmann argued that for this reason their formulation was easier to implement than the EKF and went on to suggest that its use could supplant the EKF in virtually all applications, linear or nonlinear.

In \cite{Julier1998}, Julier acknowledges that the (linear) Kalman Filter has been used successfully in many nonlinear scenarios, but notes that the use of only the first two moments of the state estimate sigma points results in the neglect of all higher order information (that is, third-order moments, or ``skew''), a potentially rich source of new and useful information relating to symmetry of the state estimate. By extending the sigma point selection scheme of the conventional unscented transform, Julier was able to present a tractable but computationally complex extension of the Kalman Filter that could predict not only the first two moments of a sigma point distribution but also the skew. Though formulated initially for unimodal distributions, Julier stated that the approach could, with additional mathematical considerations, be generalized for use with multimodal distributions. Julier's contention was that the use of higher order information could promote better performance levels in autonomous vehicle navigation. The utility of maintaining and utilizing higher order information through the use of skewed filtering was assessed by the authors in a realistic tracking scenario. However, the results turned out to be somewhat disappointing as the change in performance turned out to be minimal, presumably due to the linearity of the filter's update rule. Accordingly, research in this area continues, including examination of the use of nonlinear update rules in the filtering process.

In \cite{Julier2002}, Julier describes a novel approach to modifying the unscented transformation state estimation method. In the new approach, Julier takes the additional step of introducing a framework for scaling sigma points as part of the state estimation process. The general framework of the new methodology allows preservation of the first two moments of any set of sigma points, thus providing a construct for limiting values to either the conventional unscented transform or the modified (scaled) transform. Providing detailed mathematical validations, the author shows that the new scaling algorithm is computationally manageable in that it is, in essence, little more than the conventional unscented transformation algorithm with the addition of a simple post-processing step, the only difference being the inclusion of an extra correction term. Thus, the new algorithm's computational and storage costs are similar to that of the non-scaled transformation. The performance level of the scaled UT is thus demonstrably superior to the unscaled UT for propagating the two lower-order moments of a sigma point distribution.

In \cite{Julier2004} Julier and Uhlmann discuss the application of the EKF as an estimation algorithm and the associated difficulties in doing so. Because the EKF is fundamentally a linearizing approach to estimation, its effectiveness is thus tied to the veracity of the local linearity assumption for the system under scrutiny. These limitations led to the development of the UT for nonlinear applications. In this paper, Julier and Uhlmann describe the UT and its benefits, including easier implementation and improved accuracy. The UT offers greater accuracy and reliability by applying higher order information using sigma points to the traditional mean and covariance information associated with linear applications. The authors provide examples, which may be tailored to various process and observation models, that show how the UT overcomes the limitations of the EKF.

\section{Visual-Inertial Navigation (VIN)}

In \cite{Klein2007}, Georg Klein and David Murray proposed a method for tracking a handheld camera in unknown environments for use in small augmented reality (AR) workspaces. In contrast to many previous SLAM-based approaches to camera tracking, Klein and Murray split the tracking and mapping functions into two separate computational tasks. They performed these tasks on a dual-core computer utilizing parallel threads, with one thread directly tracking erratic motion of the hand-held camera and the other thread constructing a 3D map of the environment. Through the use of this Parallel Tracking and Mapping (PTAM) algorithm, Klein and Murray were able to take advantage of computationally expensive batch-optimization techniques for map reconstruction which were rarely ever used in real-time applications previously. This, in turn, allowed Klein and Murray to forego the common approach of creating a sparse map of high quality features in favor of a much denser map whose features could vary widely in quality. The resulting system could produce detailed maps tracking thousands of features at frame-rate and could recover gracefully from a variety of intermittent tracking failures. That being said, the researchers made certain relaxing assumptions regarding the scenes which would be tracked. PTAM, by nature of its orientation toward AR applications, operates best in small, static, planar environments (such as on the surface of a desk or the floor of an office). PTAM's value to the robotics community quickly became obvious due to its independence of \textit{a priori} knowledge of the scene and its minimal initialization procedure (explored in Chapter~tk). 

Four years later, Stephan Weiss et al. presented a VIN system for autonomous UAV navigation which employed PTAM \cite{Weiss2011}. The researchers presented the results of several experiments in which a UAV equipped with only a monocular camera and inertial sensors navigated through unknown environments without the aid of GPS satellites or other external sensing infrastructure. All calculations were performed online in real time using an EKF framework, proving that this minimalist combination of sensors could be employed in real-world GPS-compromised flight scenarios to great effect. At approximately the same time, Shen et al. \cite{Shen2011} conducted similar experiments aimed at stable indoor flight and GPS-denied localization in constrained multi-floor environments with  The research distinguishes itself by emphasizing the use of onboard sensors only, as well as fully autonomous, real-time internal computational capabilities, with no hands-on user interaction beyond basic high-level commands. The research extends to multi-floor UAV operation with loop closure. It also addresses specially designed controllers to help compensate for sudden changes in wind velocity and air flow as the UAV traverses constrained low-clearance areas with potentially strong aerodynamic disturbances.

In \cite{Weiss2011_2} Weiss and Siegwart went on to tackle the problem of metric scale in monocular VIN systems. The researchers developed a general algorithm that provides metric scale to monocular visual odometry and monocular SLAM systems using IMU data. The authors accomplished the development of the metric scale by the addition of an inertial sensor with a three-axis accelerometer and gyroscope. Weiss and Siegwart created a modular solution that is based on an EKF and provides both simulated results and data-based results. In this paper, the authors discuss their unique approach, its applications, versatility, and reliability of their estimating algorithm for visual odometry, such as visual SLAM, in real time. 

In 2012, Weiss et al. built upon this metric scale algorithm to present a versatile sensor fusion framework for autonomous flight \cite{Weiss2012}. Due to latency, noise, and arbitrary scaling within the output of a UAV's sensors, it is both impractical and ill-advised to incorporate this sensor output for position control without calibration or post-processing. They addressed these problems using an EKF-SLAM formulation which fuses pose measurements with inertial sensors. The researchers not only estimate pose and velocity of the UAV, but also estimate sensor biases, scale position measurements, and perform inter-sensor self-calibration in real time. Their research demonstrates that the proposed framework is capable of running entirely onboard a UAV, performing state prediction at a rate of 1~kHz. Their results illustrate that this approach is able to handle measurement delays (up to 500~ms), sensor noise (with positional standard deviation up to 20~cm), and slow update rates (as low as 1~Hz) while dynamic maneuvers are still possible. Weiss et al. go on to present a detailed quantitative performance evaluation of the system under the influence of different disturbance parameters and different sensor setups to highlight the versatility of their approach. That same year, Weiss et al. developed this system further, adding a speed-estimation module to their framework which fuses IMU and vision data to turn the monocular camera into a metric body-speed sensor \cite{Weiss2012_2}. They then demonstrated how this module could be used for self-calibration of the UAV's onboard sensor suite in real time.

Shortly thereafter, Huang et al. \cite{Huang2013} presented solutions to two UKF limitations that exist in current state-of-the-art SLAM systems. Specifically, the researchers addressed the problems of cubic complexity in the number of state pose estimates, and the inconsistencies in those estimates caused by a mismatch between the observability properties of statistically-linearized UKF systems and the observability properties of nonlinear systems. To address the problem of cubic complexity, they introduced a novel sampling strategy which produces a constant computational cost. This sampling method, while linear in the prediction phase, is quadratic in the update phase. Although this new sampling strategy was primarily proposed for resolving the aforementioned SLAM problem, the researchers stressed that it has potential usefulness in other nonlinear estimation applications. To address the problem of inconsistency in state estimations, Huang et al. proposed a new UKF algorithm which, due to the imposition of observability constraints, ensures that the linear regression computations of the modified UKF system produce results similar to those of nonlinear SLAM systems and, in the process, provide improved accuracy and consistency in state estimations. Importantly, the research team validated their results with both real-world and simulation experiments.

In 2013, Simon Lynen et al. \cite{Lynen2013} presented a generic framework based on the EKF-SLAM system developed in \cite{Weiss2012} to overcome known limitations in fusing information transmitted from multiple sensors in the navigation of robots. The authors demonstrate that their Multi-Sensor-Fusion EKF framework is capable of processing measurements from an unlimited number of sensors, as well as sensor types, while simultaneously performing online self-calibrations of the overall sensor suite. Designed to be modular, the framework allows seamless handling of sensor signals during operation while performing other complex, iterative calculations to achieve near-optimal linearization points for state updates.

[Engel 2013] Engel et al. propose a novel direct monocular SLAM algorithm unlike that of existing direct approaches which embrace pure visual odometry. The novelty of the authors' approach is that it permits the building of consistent, accurate, large-scale 3D maps of the environment while simultaneously tracking camera motion, incorporating any scale-drift in the environment and allowing for the detection and correction of any accumulated drift. The system is capable of running real-time on a central processing unit and as visual odometry on a modern smartphone.

[Rogers III 2014] Rogers et al. presented a methodology for overcoming some of the constraining conditions encountered in a GPS-guided autonomous robotic system, such as occlusion (blocking of GPS signals) and multipath (reception of indirect signals due to environmental reflections) and potentially to ameliorate the effects of jamming or spoofing resulting from adversarial activities. Specifically, the methodology incorporated GPS measurements into a feature-based mapping system, thus providing geo-referenced coordinates allowing for better execution of high-level missions and providing the ability to correct accumulated mapping errors over the course of long-term operations in both indoor and outdoor environments.

[Faessler 2015] Faessler et al. report on the development and demonstration of a low-cost, low-weight, vision-based quadrotor UAV with onboard sensing, computation, and control capabilities. These onboard capabilities eliminated reliance on external positioning systems such as GPS or motion capture systems. This development moves the UAV from its current line-of-sight control state to wireless communications with the ability to execute intricate processes autonomously and to transmit live feedback to a user. Reporting on both indoor and outdoor experiments, the authors believe that such a vehicle potentially would be a great enhancement in search-and-rescue missions, disaster response, and remote inspection of terrain. 
