\chapter{Future Work}

\section{Improving \texttt{kalman\_sense}}

Experimentation with \texttt{kalman\_sense} has revealed a number of areas for improvement. Speaking generally, the system needs enhancements to become more accurate and more robust to sensor dropout. Further development of this work would likely center on three main areas:
\begin{enumerate}
\item Integration of new sensors,
\item Improvements for current sensors, and
\item Refinements to the underlying algorithm.
\end{enumerate}
Each of these could produce a marked improvement to the system in accuracy, robustness, or both. Particular use cases, Concepts of Operations (CONOPS), and desired performance metrics would likely drive the selection of which of these areas to tackle.

\subsection{Integration of New Sensors}
The accuracy and robustness of the system could be augmented by the integration of additional sensors, including but not limited to
\begin{enumerate}
\item One or more GPS receivers (particularly Real Time Kinematic\footnote{\url{https://en.wikipedia.org/wiki/Real_Time_Kinematic}} GPS),
\item A pressure altimeter,
\item One or more laser rangefinders,
\item One or more forward-facing cameras (preferably depth cameras, such as RGB-D),
\item One-dimensional, multi-dimensional, or scanning LIDAR\footnote{``Light Detection and Ranging,'' \url{https://en.wikipedia.org/wiki/Lidar}}.
\end{enumerate}
We have previously mentioned work from the GRASP Lab (\cite{Shen2011}) that has demonstrated the efficacy of systems similar to \texttt{kalman\_sense} in indoor-outdoor transitions and in navigating confined spaces with an expanded suite of sensors. In the case where more than one sensor can be used to observe a given vehicle state variable, those multiple sensors can be used to check one another and even perform real-time, in-air calibration. The system developed in this thesis has the advantage of being hardware-minimal in that it depends on only two sensors (the IMU and ventral camera), but this convenience comes at the cost of robustness as either sense presents a single point of failure. Moreover, the sensors have no overlap in that neither can observe any of the states observed by the other. This eliminates the possibility of checking one sensor against the other with high confidence. Introducing a ventral laser rangefinder or pressure altimeter would allow for much more precise measurement of the vehicle's altitude and would allow for in-flight re-initialization of any metric SLAM/VO algorithm.

With the exception of certain sensors such as scanning LIDAR, which can cost tens of thousands of dollars, and RTK-GPS, which often falls in the same price range, these proposed new sensors would be inexpensive additions to the vehicle. Given the sophistication of current miniaturized sensors, it is not unreasonable to expect sub-meter or centimeter-level position accuracy from vehicles weighing fewer than fifteen pounds (including a substantial sensor payload) and costing less than 20,000~USD. It has been the case for a number of years now that meter-level accuracy could be taken for granted with ``toy'' quadcopters using only MEMS\footnote{\url{https://en.wikipedia.org/wiki/Microelectromechanical_systems}} IMUs and sub-\$100 GPS receivers. The trend of miniaturization has made more and more sensors of better and better quality increasingly available in the weight- and cost-constrained world of aerial robotics. A variety of inexpensive off-the-shelf autopilots, such as the Pixhawk~2.1\footnote{\url{http://www.proficnc.com/}}, already boast triple-redundant IMUs and support for multiple GPS modules. Many of the hardware integration challenges that once plagued hobbyists and researchers have been eliminated by popular demand for user-friendly drones.

The organization of \texttt{kalman\_sense}'s code base is such that the integration of new sensors would require only the addition of new callback functions and ROS subscribers, as opposed to a full redesign or any major edits to the existing code. By a similar token, a new SLAM or VO algorithm could also be used in place of PTAM, allowing an ``apples-to-apples'' comparison of different vision algorithms. For example, Donavanik et al.\ (\cite{Donavanik2016}) have identified a new algorithm known as ORB-SLAM (\cite{Mur-Artal2015}) as a promising candidate for robust SLAM, already implemented in ROS. Because of ROS's sophisticated ecosystem of interoperable packages and message formats, any pose sensor employing the same message type as PTAM could plug in to \texttt{kalman\_sense} in a matter of seconds.

Much of the design thinking that went into the design of the \texttt{kalman\_sense} package was focused on this particular possibility. The aircraft of the future are rapidly becoming ``hundred-eyed monsters''---vehicles laden with a vast suite of heterogeneous sensors, the outputs of which are at any given time being used not only for inner-loop and outer-loop flight control but also for self-calibration, real-time diagnostics, and operator telemetry. Future UAVs will be akin to floating laboratories, carrying numerous means of measurement for all manner of self-sensing as well as scientific applications.

\subsection{Improvements for Current Sensors}

For improved pose measurements, a more robust implementation of PTAM could be written and the same experiments could be repeated for comparison. PTAM's rotation errors and inability to eliminate lens distortion pose severe limitations to its effectiveness in small UAS navigation. Moreover, if a rewritten implementation were able to interface to a downward-facing rangefinder, the initialization process could be eliminated altogether. The problem with this is that making these changes would likely require a major rewrite, a project that could only feasibly be undertaken by an experienced team of computer vision researchers and software developers. The mere cost in terms of both time and labor would likely make this an unappealing proposition, especially if other ready-made SLAM/VO algorithms were available to serve as PTAM replacements.

On that same note, the system's processing power could always be augmented through the inclusion of a powerful onboard computer and one or more Graphics Processing Units\footnote{\url{https://en.wikipedia.org/wiki/Graphics_processing_unit}} (GPUs).

\subsection{Refinements to the Underlying Algorithm}





\section{Future Experiments}

\section{System Applications}
