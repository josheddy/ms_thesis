\chapter{Algorithm Design and Implementation} \label{ch:alg_design}

\section{UKF Formulation} \label{sec:ukf_formulation}

\subsection{Prediction Step}

We begin by defining the following quantities:
%
\begin{align} \label{eq:state_vars}
\mathbf{p} &= \left\lbrace x, y, z \right\rbrace ^{T} \\
\mathbf{q} &= \left\lbrace q_{x}, q_{y}, q_{z}, q_{w} \right\rbrace ^{T} \\
\mathbf{v} &= \left\lbrace \dot{x}, \dot{y}, \dot{z} \right\rbrace ^{T} \\
\mathbf{\Omega} &= \left\lbrace \omega_{x}, \omega_{y}, \omega_{z} \right\rbrace ^{T} \\
\mathbf{a} &= \left\lbrace \ddot{x}, \ddot{y}, \ddot{z} \right\rbrace ^{T}
\end{align}
%
The vectors $\mathbf{p}$, $\mathbf{v}$, and $\mathbf{a}$ represent the vehicle's position, velocity, and acceleration, respectively. The quaternion\footnote{From here on, all quaternion quantities are represented according to the convention $\mathbf{q} = \left\lbrace q_{x}, q_{y}, q_{z}, q_{w} \right\rbrace ^{T}$, where $q_{w}$ is the scalar component and is always placed in the last position. This convention was chosen to maintain consistency with the Eigen library's internal representation of quaternions.} $\mathbf{q}$ represents the vehicle's orientation and the vector $\mathbf{\Omega}$ represents the vehicle's angular rates. We now define the state vector $\mathbf{x}$ as
%
\begin{equation}
\mathbf{x} = 
\left\lbrace
    \mathbf{p}^{T},
    \mathbf{q}^{T},
    \mathbf{v}^{T},
    \mathbf{\Omega}^{T},
    \mathbf{a}^{T}
\right\rbrace ^{T}.
\end{equation}
%
and let $n = 16$ represent the number of state variables.

We now define the following constants:
%
\begin{align}
\alpha &= 10^{-3} \nonumber \\
\kappa &= 0 \\
\beta &= 2 \nonumber \\
\lambda &= \alpha^{2} \left( n + \kappa \right) - n \nonumber
\end{align}
%
The constants $\alpha$ and $\kappa$ control the spread of sigma points chosen within the filter. The value of $\beta$ governs what distribution is assumed for the states $\mathbf{x}$. Setting $\beta = 2$ is optimal for a Gaussian state distribution, which we assume throughout. With these constants defined, we can now describe the selection of sigma points.

Let $\mathbf{P} \in \mathbb{R}^{n \times n}$ be the covariance matrix associated with the state $\mathbf{x}$. A set of $2n + 1$ sigma points is then derived from $\mathbf{x}$ and $\mathbf{P}$ as
%
\begin{align}
\mathbf{\chi}^{0}_{k-1 | k-1} &= \mathbf{x}_{k-1 | k-1} \nonumber\\
\mathbf{\chi}^{i}_{k-1 | k-1} &= \mathbf{x}_{k-1 | k-1} + \left( \sqrt{\left( n + \lambda \right) \mathbf{P}_{k-1 | k-1}} \right)_{i}, &&i = 1, \dots, n \\
\mathbf{\chi}^{i}_{k-1 | k-1} &= \mathbf{x}_{k-1 | k-1} - \left( \sqrt{\left( n + \lambda \right) \mathbf{P}_{k-1 | k-1}} \right)_{i-n}, &&i = n+1, \dots, 2n, \nonumber
\end{align}
%
where $\mathbf{\chi}^{i}$ is the $i$-th sigma point and $\left( \sqrt{\left( n + \lambda \right) \mathbf{P}_{k-1 | k-1}} \right)_{i}$ is the $i$-th column of the matrix $\sqrt{\left( n + \lambda \right) \mathbf{P}_{k-1 | k-1}}$. The matrix square root $\mathbf{A}$ of a matrix $\mathbf{B}$ is defined here as
%
\begin{equation}
\mathbf{A} \mathbf{A}^{T} = \mathbf{B}
\end{equation}
%
and is computed via Cholesky decomposition.

To predict the next state, these sigma points are propagated through the nonlinear process function $f$ (defined in Section~\ref{Process_Model}):
%
\begin{equation}
\mathbf{\chi}^{i}_{k | k-1} = f \left( \mathbf{\chi}^{i}_{k-1 | k-1} \right), \quad i = 0, \dots, 2n.
\end{equation}
%
These new sigma points are then used to predict the next state and covariance:
%
\begin{align}
\hat{\mathbf{x}}_{k | k-1} &= \sum^{2n}_{i=0} W^{i}_{s} \mathbf{\chi}^{i}_{k | k-1} \\
\mathbf{P}_{k | k-1} &= \left( \sum^{2n}_{i=0} W^{i}_{c} \left( \mathbf{\chi}^{i}_{k | k-1} - \hat{\mathbf{x}}_{k | k-1} \right) \left( \mathbf{\chi}^{i}_{k | k-1} - \hat{\mathbf{x}}_{k | k-1} \right)^{T} \right) + \mathbf{Q}_{k},
\end{align}
%
where the state weights $W_{s}$ and covariance weights $W_{c}$ are defined as
%
\begin{align}
W^{0}_{s} &= \dfrac{\lambda}{n + \lambda} \nonumber \\
W^{0}_{c} &= \dfrac{\lambda}{n + \lambda} + \left( 1 - \alpha^{2} + \beta \right) \\
W^{i}_{s} &= W^{i}_{c} = \dfrac{1}{2 \left(n + \lambda \right)}, \quad i = 1, \dots, 2n \nonumber
\end{align}
%
and the process noise covariance matrix $\mathbf{Q}_{k}$ is defined in Section~\ref{sec:Q_Matrix}.


\subsection{Correction Step}

Given the belief defined by $\mathbf{x}_{k | k-1}$ and $\mathbf{P}_{k | k-1}$, we compute $2n + 1$ sigma points again as
%
\begin{align}
\mathbf{\chi}^{0}_{k | k-1} &= \mathbf{x}_{k | k-1} & \nonumber\\
\mathbf{\chi}^{i}_{k | k-1} &= \mathbf{x}_{k | k-1} + \left( \sqrt{\left( n + \lambda \right) \mathbf{P}_{k | k-1}} \right)_{i}, &&i = 1, \dots, n \\
\mathbf{\chi}^{i}_{k | k-1} &= \mathbf{x}_{k | k-1} - \left( \sqrt{\left( n + \lambda \right) \mathbf{P}_{k | k-1}} \right)_{i-n}, &&i = n+1, \dots, 2n. \nonumber
\end{align}
%
Next, the sigma points are projected through the observation function $h$ (defined in Section~\ref{Observation_Model}):
%
\begin{equation}
\mathbf{\gamma}^{i}_{k} = h \left( \mathbf{\chi}^{i}_{k | k-1} \right), \quad i = 0, \dots, 2n.
\end{equation}

Let $m = 7$ represent the number of measurements taken from each PTAM message. Each of these messages is read into \texttt{kalman\_sense} as an $m$-dimensional measurement vector $\mathbf{z}_{k}$ of the form
%
\begin{equation}
\mathbf{z}_{k} = \left\lbrace x, y, z, q_{x}, q_{y}, q_{z}, q_{w} \right\rbrace ^{T} _{meas.} .
\end{equation}
%
The predicted measurement vector $\hat{\mathbf{z}}_{k}$ and measurement noise covariance $\mathbf{P}_{zz}$ are then computed as
%
\begin{align}
\hat{\mathbf{z}}_{k} &= \sum^{2n}_{i=0} W^{i}_{s} \mathbf{\gamma}^{i}_{k} \\
\mathbf{P}_{zz} &= \left( \sum^{2n}_{i=0} W^{i}_{c} \left( \mathbf{\gamma}^{i}_{k} - \hat{\mathbf{z}}_{k} \right) \left( \mathbf{\gamma}^{i}_{k} - \hat{\mathbf{z}}_{k} \right)^{T} \right) + \mathbf{R},
\end{align}
%
where $\mathbf{R}$ is the measurement noise covariance matrix defined in Section~\ref{sec:R_Matrix}. The state-measurement cross-covariance $\mathbf{P}_{xz}$ is then defined as
%
\begin{equation}
\mathbf{P}_{xz} = \sum^{2n}_{i=0} W^{i}_{c} \left( \mathbf{\chi}^{i}_{k | k-1} - \hat{\mathbf{x}}_{k | k-1} \right) \left( \mathbf{\gamma}^{i}_{k} - \hat{\mathbf{z}}_{k} \right)^{T} .
\end{equation}
%
Next, we compute the Kalman gain $\mathbf{K}_{k}$ per the definition
%
\begin{equation}
\mathbf{K}_{k} = \mathbf{P}_{xz} \mathbf{P}^{\,-1}_{zz}.
\end{equation}
%
The corrected state $\hat{\mathbf{x}}_{k | k}$ is then the sum of the predicted state and the innovation, weighted by $\mathbf{K}_{k}$:
%
\begin{equation}
\hat{\mathbf{x}}_{k | k} = \hat{\mathbf{x}}_{k | k-1} + \mathbf{K}_{k} \left( \hat{\mathbf{z}}_{k} - \mathbf{z}_{k} \right) .
\end{equation}
%
The corrected covariance $\mathbf{P}_{k | k}$ is the difference between the predicted covariance and the predicted measurement covariance, weighted by the Kalman gain:
%
\begin{equation}
\mathbf{P}_{k | k} = \mathbf{P}_{k | k-1} - \mathbf{K}_{k} \mathbf{P}_{k | k-1} \mathbf{K}_{k}^{T} .
\end{equation}

\subsection{Process Model} \label{Process_Model}

To propagate the vehicle's state forward in time, we perform a number of integral operations on the linear accelerations and angular rates measured by the IMU. To determine the orientation of the vehicle at some time $k$, we integrate the measured angular rate vector $\mathbf{\Omega}_{k}$ per the relationship
%
\begin{equation}
\mathbf{q}_{k | k-1} = \mathbf{q}_{k-1} + \frac{1}{2} \mathbf{\Theta} \left( \mathbf{\Omega}_{k} \right) \mathbf{q}_{k-1} \Delta t ,
\end{equation}
%
where $\mathbf{\Theta} \left( \mathbf{\Omega}_{k} \right) \in \mathbb{R}^{4 \times 4}$ is the angular rate integration matrix defined by
%
\begin{equation}
\mathbf{\Theta} \left( \mathbf{\Omega}_{k} \right) =
\begin{bmatrix}
0 & \omega_{z} & -\omega_{y} & \omega_{x} \\
-\omega_{z} & 0 & \omega_{x} & \omega_{y} \\
\omega_{y} & -\omega_{x} & 0 & \omega_{z} \\
-\omega_{x} & -\omega_{y} & -\omega_{z} & 0
\end{bmatrix} .
\end{equation}
%
We rotate the measured acceleration vector $\mathbf{a}_{k}$ into the inertial frame using the equation \todo{Have Sam look over this}
%
\begin{equation}
\mathbf{a}_{k | k-1} = R^{g}_{b} \left( \mathbf{q}_{k-1} \right) \mathbf{a}_{k} ,
\end{equation}
%
where $R^{g}_{b} \left( \mathbf{q}_{k-1} \right)$ is the rotation matrix representation of the previous quaternion $\mathbf{q}_{k-1}$. \todo{What does this work out to be?}


\subsection{Observation Model} \label{Observation_Model}

\subsubsection{Quaternion Continuity Correction}

\subsubsection{Pseudovelocity Correction}

\subsection{Process Noise Covariance} \label{sec:Q_Matrix}

The process noise covariance matrix $\mathbf{Q}_{k} \in \mathbb{R}^{n \times n}$ is symmetric, time-dependent, and positive definite. We assume that its nonzero coefficients are a function of multiple integrations between the linear accelerations and angular velocities measured by the vehicle's 3-axis accelerometer and 3-axis gyroscope.

We assume that all axes of the accelerometer and gyroscope exhibit white noise with known standard deviations $\sigma_{a}$ and $\sigma_{\omega}$, respectively\footnote{This claim of equal standard deviations between axes is supported by the IMU data sheet.}. We further assume that the cross-axis covariance terms (that is, between any two accelerometer axes or between any two gyroscope axes) are zero.

For the sake of convenient estimation, we assume that the accelerometer and gyroscope variance terms grow linearly over each discrete time step $\Delta t$. Thus, in the case of the $x$-axis accelerometer and the $x$-axis gyroscope, the corresponding terms of $\mathbf{Q}_{k}$ would be
%
\begin{equation}
Q_{a_{x},a_{x}} = \sigma_{a} \Delta t
\end{equation}
%
and
%
\begin{equation}
Q_{\omega_{x},\omega_{x}} = \sigma_{\omega} \Delta t ,
\end{equation}
%
respectively. We can now estimate the other nonzero terms of $\mathbf{Q}_{k}$ according to their integral relationships with the acceleration and angular velocity measurements.

\todo{integral equations}

We assume no coupling between the angular quantities ($\mathbf{q}$ and $\mathbf{\Omega}$) and the linear quantities ($\mathbf{p}$, $\mathbf{v}$, and $\mathbf{a}$), making the process noise covariance matrix largely sparse. This assumption logically stems from the small angle assumption. Because the IMU runs at 250~Hz, we assume that the vehicle makes only small rotations between IMU measurements. 

\todo{full Q matrix}


\subsection{Measurement Noise Covariance} \label{sec:R_Matrix}

The matrix $\mathbf{R} \in \mathbb{R}^{m \times m}$ models the covariance between measurements made by the pose sensor, PTAM. Like the process noise covariance $\mathbf{Q}_{k}$, the measurement noise covariance matrix $\mathbf{R}$ is symmetric and positive definite. However, for the purposes of this experiment, $\mathbf{R}$ is assumed to be time-invariant due to nearly constant feature density in the experimental scene. Because the vehicle camera moves across the scene at an almost constant height (that is, at a nearly constant distance to the features it observes on the floor), the measurement noise covariance of the pose sensor is assumed to be approximately constant in time. The coefficients of $\mathbf{R}$ were estimated by numerically computing the covariances between raw measurements from PTAM and the ground truth supplied by Vicon.

The resulting $\mathbf{R}$ matrix is as follows:
%
\todo{R Matrix}

\section{Software Design Considerations}

Much of the impetus for creating the \texttt{kalman\_sense} package came from a desire to create a generic UKF framework for estimating the state of an arbitrary system using any number of relative and absolute sensors. To achieve this, the \texttt{kalman\_sense} package is organized in an object-oriented manner around an overarching abstract class called \texttt{UnscentedKf}. This abstract class contains a number of methods performing the different mathematical operations defined in Section~\ref{sec:ukf_formulation}. These methods have been written in a generic manner to enable easy extension of \texttt{UnscentedKf} by subclasses containing concrete implementations of various systems. Currently, the package contains only one subclass, known as \texttt{QuadUkf}. This subclass contains methods and data structures related directly to estimating the state of a quadcopter or other rotorcraft UAV.

The \texttt{UnscentedKf} class encapsulates the generic mathematics of the UKF without knowledge of particular system constraints. This class does little other than matrix mathematics and is designed to take as input the number of a system's states $n$ and its number of sensors $m$. With this information, \texttt{UnscentedKf} is able to populate a set of mean and covariance weights and intelligently perform all of the requisite linear algebra for the UKF formulation. All other knowledge of particular states, sensors, vehicle geometry, and other metrics is hidden within subclasses such as \texttt{QuadUkf}.

\texttt{UnscentedKf} behaves in a manner similar to a Java interface in that it requires the extending class to supply functions codifying a process model and an observation model for the system under scrutiny. These two functions, along with $n$ and $m$, form the entirety of what \texttt{UnscentedKf} ``knows'' about the vehicle. All other details, including the fact that the class is being used in a ROS environment, are hidden from \texttt{UnscentedKf}. It is worth noting that \texttt{UnscentedKf}'s only dependency is on the Eigen C++ linear algebra library\footnote{\url{www.eigen.tuxfamily.org}}.

The subclass (\texttt{QuadUkf} for the remainder of this thesis) handles all of the ROS communications for the given system. Specifically, this class has callback functions for receiving sensor data and is responsible for publishing state and covariance estimates.

